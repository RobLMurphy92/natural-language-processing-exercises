{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "headers = {'User-Agent': 'Codeup Data Science'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get(url, headers = headers)\n",
    "html_raw = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(html_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_raw, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.find('h1').text\n",
    "body = soup.find(class_ = \"jupiterx-post-body\" ).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So need to clean up the body and title for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.) Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "Lowercase everything\n",
    "Normalize unicode characters\n",
    "Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercasing everything withing the string\n",
    "body = body.lower()\n",
    "#normalizing, removing any inconsistencies in unicode character encoding, then encode to conver to ASCII, ignore any errors during conversion which will drop everything.\n",
    "# decode turning the bytes object back into a string\n",
    "body = unicodedata.normalize('NFKD', body)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(article):\n",
    "    '''\n",
    "    This function will take any text corpus and lower case everything and \n",
    "    remove any accented characters, non-ASCII characters. Will do this through encode which converts to ascii,\n",
    "    then decode which will turn the bytes object back into a string.\n",
    "    '''\n",
    "    #lower casing everything for normalicy\n",
    "    article = article.lower()\n",
    "    #ridding of non-ascii characters by conversion, then changing the bytes object backinto string.\n",
    "    article = unicodedata.normalize('NFKD', body).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    \n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in Glassdoors #1 Best Job in America.\\nData Science is a method of providing actionable intelligence from data. The data revolution has hit San Antonio, resulting in an explosion in Data Scientist positions across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. Weve even seen UTSA invest $70 M for a Cybersecurity Center and School of Data Science. We built a program to specifically meet the growing demands of this industry.\\nOur program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nWe focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee  just like our existing Web Dev program. Were focusing on Data Science with Python, SQL, and ML, covered in 14 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning  regression; 6) Supervised machine learning  classification; 7) Unsupervised machine learning  clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\\nApplications are now open for Codeups first Data Science cohort, which will start class on February 4, 2019. Hurry  there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\\nIf you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\\n\\nFacebookTwitterLinkedIn'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_clean(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.) Define a function named tokenize. It should take in a string and tokenize all the words in the string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function will tokenize the string, essentially break words and any punctuation left over into discrete units.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(article):\n",
    "    '''\n",
    "    function will tokenize the string, essentially break words and any punctuation left over into discrete units.\n",
    "    '''\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    article = tokenizer.tokenize(article, return_str=True)\n",
    "    \n",
    "    return article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The rumors are true ! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator , with only 25 seats available ! This immersive program is one of a kind in San Antonio , and will help you land a job in Glassdoor ’ s #1 Best Job in America.\\nData Science is a method of providing actionable intelligence from data. The data revolution has hit San Antonio , resulting in an explosion in Data Scientist positions across companies like USAA , Accenture , Booz Allen Hamilton , and HEB. We ’ ve even seen UTSA invest $ 70 M for a Cybersecurity Center and School of Data Science. We built a program to specifically meet the growing demands of this industry.\\nOur program will be 18 weeks long , full-time , hands-on , and project-based. Our curriculum development and instruction is led by Senior Data Scientist , Maggie Giust , who has worked at HEB , Capital Group , and Rackspace , along with input from dozens of practitioners and hiring partners. Students will work with real data sets , realistic problems , and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing , interviewing , and continuing education to prepare for a smooth transition to the workforce.\\nWe focus on applied data science for immediate impact and ROI in a business , which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We ’ re focusing on Data Science with Python , SQL , and ML , covered in 14 modules : 1 ) Fundamentals ; 2 ) Applied statistics ; 3 ) SQL ; 4 ) Python ; 5 ) Supervised machine learning – regression ; 6 ) Supervised machine learning – classification ; 7 ) Unsupervised machine learning – clustering ; 8 ) Time series analysis ; 9 ) Anomaly detection ; 10 ) Natural language processing ; 11 ) Distributed machine learning ; 12 ) Advanced topics ( deep learning , NoSQL , cloud deployment , etc. ) ; 13 ) Storytelling with data ; and 14 ) Domain expertise development.\\nApplications are now open for Codeup ’ s first Data Science cohort , which will start class on February 4 , 2019. Hurry – there are only 25 seats available ! To further our mission of cultivating inclusive growth , scholarships will be available to women , minorities , LGBTQIA+ individuals , veterans , first responders , and people relocating to San Antonio.\\nIf you want to learn about joining our program or hiring our graduates , email datascience@codeup.com ! \\n\\nFacebookTwitterLinkedIn'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = tokenize_func(body)\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.) Define a function named stem. It should accept some text and return the text after applying stemming to all the words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the rumor are true ! the time ha arrived. codeup ha offici open applic to our new data scienc career acceler , with onli 25 seat avail ! thi immers program is one of a kind in san antonio , and will help you land a job in glassdoor ’ s #1 best job in america. data scienc is a method of provid action intellig from data. the data revolut ha hit san antonio , result in an explos in data scientist posit across compani like usaa , accentur , booz allen hamilton , and heb. We ’ ve even seen utsa invest $ 70 M for a cybersecur center and school of data science. We built a program to specif meet the grow demand of thi industry. our program will be 18 week long , full-tim , hands-on , and project-based. our curriculum develop and instruct is led by senior data scientist , maggi giust , who ha work at heb , capit group , and rackspac , along with input from dozen of practition and hire partners. student will work with real data set , realist problem , and the entir data scienc pipelin from collect to deployment. they will receiv profession develop train in resum write , interview , and continu educ to prepar for a smooth transit to the workforce. We focu on appli data scienc for immedi impact and roi in a busi , which is how we can back it all up with a 6 month tuition refund guarante – just like our exist web dev program. We ’ re focus on data scienc with python , sql , and ML , cover in 14 modul : 1 ) fundament ; 2 ) appli statist ; 3 ) sql ; 4 ) python ; 5 ) supervis machin learn – regress ; 6 ) supervis machin learn – classif ; 7 ) unsupervis machin learn – cluster ; 8 ) time seri analysi ; 9 ) anomali detect ; 10 ) natur languag process ; 11 ) distribut machin learn ; 12 ) advanc topic ( deep learn , nosql , cloud deploy , etc. ) ; 13 ) storytel with data ; and 14 ) domain expertis development. applic are now open for codeup ’ s first data scienc cohort , which will start class on februari 4 , 2019. hurri – there are onli 25 seat avail ! To further our mission of cultiv inclus growth , scholarship will be avail to women , minor , lgbtqia+ individu , veteran , first respond , and peopl reloc to san antonio. If you want to learn about join our program or hire our graduat , email datascience@codeup.com ! facebooktwitterlinkedin'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the nltk stemmer object, then use it\n",
    "\n",
    "def stem(article):\n",
    "    '''\n",
    "    takes in string and will stem transformation to all words within the specifiec string\n",
    "    '''\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in article.split()]\n",
    "    article_stemmed = ' '.join(stems)\n",
    "    return article_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.) Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lexicographically correct word (present in the dictionary),\n",
    "def lemmatize(article):\n",
    "    '''\n",
    "     this function takes in a string and utilize lemmatization on the string\n",
    "     which change word to root word which will  be lexicographically correct word (present in the dictionary).\n",
    "    '''\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    for word in article.split():\n",
    "        lemmas = [wnl.lemmatize(word) for word in article.split()]\n",
    "        article_lemmatized = ' '.join(lemmas)\n",
    "    return article_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The rumor are true ! The time ha arrived. Codeup ha officially opened application to our new Data Science career accelerator , with only 25 seat available ! This immersive program is one of a kind in San Antonio , and will help you land a job in Glassdoor ’ s #1 Best Job in America. Data Science is a method of providing actionable intelligence from data. The data revolution ha hit San Antonio , resulting in an explosion in Data Scientist position across company like USAA , Accenture , Booz Allen Hamilton , and HEB. We ’ ve even seen UTSA invest $ 70 M for a Cybersecurity Center and School of Data Science. We built a program to specifically meet the growing demand of this industry. Our program will be 18 week long , full-time , hands-on , and project-based. Our curriculum development and instruction is led by Senior Data Scientist , Maggie Giust , who ha worked at HEB , Capital Group , and Rackspace , along with input from dozen of practitioner and hiring partners. Students will work with real data set , realistic problem , and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing , interviewing , and continuing education to prepare for a smooth transition to the workforce. We focus on applied data science for immediate impact and ROI in a business , which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We ’ re focusing on Data Science with Python , SQL , and ML , covered in 14 module : 1 ) Fundamentals ; 2 ) Applied statistic ; 3 ) SQL ; 4 ) Python ; 5 ) Supervised machine learning – regression ; 6 ) Supervised machine learning – classification ; 7 ) Unsupervised machine learning – clustering ; 8 ) Time series analysis ; 9 ) Anomaly detection ; 10 ) Natural language processing ; 11 ) Distributed machine learning ; 12 ) Advanced topic ( deep learning , NoSQL , cloud deployment , etc. ) ; 13 ) Storytelling with data ; and 14 ) Domain expertise development. Applications are now open for Codeup ’ s first Data Science cohort , which will start class on February 4 , 2019. Hurry – there are only 25 seat available ! To further our mission of cultivating inclusive growth , scholarship will be available to woman , minority , LGBTQIA+ individual , veteran , first responder , and people relocating to San Antonio. If you want to learn about joining our program or hiring our graduate , email datascience@codeup.com ! FacebookTwitterLinkedIn'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = lemmatize(body)\n",
    "body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.) Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(article, extra_words, exclude_words):\n",
    "    extra_words = []\n",
    "    exclude_worss = []\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    words = article.split()\n",
    "    filtered_words = [w for w in words if w not in stopword_list]\n",
    "    article_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return article_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.) Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.) Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.) For each dataframe, produce the following columns:\n",
    "\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9.) Ask yourself:\n",
    "\n",
    "- If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
